{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72ad1a11",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652796a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "from itertools import combinations\n",
    "from sklearn.metrics import accuracy_score\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d9042b",
   "metadata": {},
   "source": [
    "### Function to calculate angles and head poses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58053135",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "from itertools import combinations\n",
    "\n",
    "# Initialize MediaPipe models\n",
    "mp_pose = mp.solutions.pose.Pose(static_image_mode=True)\n",
    "mp_fm = mp.solutions.face_mesh.FaceMesh(min_detection_confidence=0.5, min_tracking_confidence=0.35)\n",
    "\n",
    "def calculate_angle(p1, p2, p3):\n",
    "    \"\"\"Calculate the angle between three points.\"\"\"\n",
    "    a = np.array(p1)\n",
    "    b = np.array(p2)\n",
    "    c = np.array(p3)\n",
    "    ba = a - b\n",
    "    bc = c - b\n",
    "    cosine_angle = np.dot(ba, bc) / (np.linalg.norm(ba) * np.linalg.norm(bc))\n",
    "    angle = np.arccos(cosine_angle)\n",
    "    return np.degrees(angle)\n",
    "\n",
    "def process_image(image_path):\n",
    "    \"\"\"Process a single image for pose angles and head angles.\"\"\"\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Process the image with pose\n",
    "    pose_results = mp_pose.process(image)\n",
    "    pose_angles = []\n",
    "    if pose_results.pose_landmarks:\n",
    "        # Ensure landmarks are correctly referenced\n",
    "        landmarks = np.array([(lm.x, lm.y, lm.z) for lm in pose_results.pose_landmarks.landmark[:25]])\n",
    "        for combo in combinations(range(len(landmarks)), 3):\n",
    "            angle = calculate_angle(landmarks[combo[0]], landmarks[combo[1]], landmarks[combo[2]])\n",
    "            pose_angles.append(angle)\n",
    "    \n",
    "\n",
    "    # Process the image with face mesh\n",
    "    face_results = mp_fm.process(image)\n",
    "    head_angles = []\n",
    "    if face_results.multi_face_landmarks:\n",
    "        face_3d = []\n",
    "        face_2d = []\n",
    "        img_h, img_w, _ = image.shape\n",
    "        for face_landmarks in face_results.multi_face_landmarks:\n",
    "            for idx, lm in enumerate(face_landmarks.landmark):\n",
    "                if idx in [33, 263, 61, 199]:\n",
    "                    x, y = int(lm.x * img_w), int(lm.y * img_h)\n",
    "                    face_2d.append([x, y])\n",
    "                    face_3d.append([x, y, lm.z])\n",
    "\n",
    "            # Solve PnP\n",
    "            face_2d = np.array(face_2d, dtype=np.float64)\n",
    "            face_3d = np.array(face_3d, dtype=np.float64)\n",
    "            cam_matrix = np.array([[img_w, 0, img_h / 2], [0, img_w, img_w / 2], [0, 0, 1]])\n",
    "            dist_matrix = np.zeros((4, 1), dtype=np.float64)\n",
    "            _, rot_vec, _ = cv2.solvePnP(face_3d, face_2d, cam_matrix, dist_matrix)\n",
    "            rmat, _ = cv2.Rodrigues(rot_vec)\n",
    "            angles, _, _, _, _, _ = cv2.RQDecomp3x3(rmat)\n",
    "            head_angles = [angles[0] * 360, angles[1] * 360]\n",
    "\n",
    "    return pose_angles, head_angles\n",
    "\n",
    "def process_folder(folder_path, label):\n",
    "    \"\"\"Process all images in a folder and associate them with a label.\"\"\"\n",
    "    folder_data = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".jpg\"):\n",
    "            image_path = os.path.join(folder_path, filename)\n",
    "            pose_angles, head_angles = process_image(image_path)\n",
    "            folder_data.append((pose_angles + head_angles, label))\n",
    "    return folder_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a421b058",
   "metadata": {},
   "source": [
    "### Loading and processing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3887b90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_1_path = '/home/vaishnavi/MLPR_Project/Integrated_data/1'\n",
    "folder_3_path = '/home/vaishnavi/MLPR_Project/Integrated_data/3'\n",
    "folder_5_path = '/home/vaishnavi/MLPR_Project/Integrated_data/5'\n",
    "\n",
    "data_1 = process_folder(folder_1_path, 0)  # Label 0 for folder 1\n",
    "data_3 = process_folder(folder_3_path, 1)  # Label 1 for folder 3\n",
    "data_5 = process_folder(folder_5_path, 2)  # Label 2 for folder 5\n",
    "\n",
    "all_data = data_1 + data_3 + data_5\n",
    "np.random.shuffle(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7501fff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = max(len(x) for x, _ in all_data)\n",
    "padded_data = [(np.pad(x, (0, max_length - len(x)), 'constant'), y) for x, y in all_data]\n",
    "\n",
    "X = np.array([x for x, _ in padded_data])\n",
    "y = np.array([y for _, y in padded_data])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf9ff34",
   "metadata": {},
   "source": [
    "### Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aceb8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ab5da1",
   "metadata": {},
   "source": [
    "### XG Boost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c9290c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train the XGBoost classifier\n",
    "xgb_clf = xgb.XGBClassifier(objective='multi:softmax', num_class=3, num_estimators = 300, learning_rate=0.1, max_depth=5)\n",
    "xgb_clf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc24979",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d4ac68",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_xgb = xgb_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e21483",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "accuracy_xgb = accuracy_score(y_test, y_pred_xgb)\n",
    "print(f'XGBoost Test Accuracy: {accuracy_xgb}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8541d2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = precision_score(y_test, y_pred_xgb, average='weighted')\n",
    "recall = recall_score(y_test, y_pred_xgb, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred_xgb, average='weighted')\n",
    "conf_matrix = confusion_matrix(y_test, y_pred_xgb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6106f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'XGBoost Test Accuracy: {accuracy_xgb}')\n",
    "print(f'XGBoost Precision: {precision}')\n",
    "print(f'XGBoost Recall: {recall}')\n",
    "print(f'XGBoost F1 Score: {f1}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8032f05",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Calculate the confusion matrix again if needed\n",
    "conf_matrix = confusion_matrix(y_test, y_pred_xgb)\n",
    "\n",
    "# Plotting using Seaborn\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='g', cmap='Blues', xticklabels=[1, 3, 5], yticklabels=[1, 3, 5])\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e1f79f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "xgb_clf.save_model('xgboost_model.bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e37791",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bbbd322",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "svm_model = SVC()\n",
    "svm_model.fit(X_train, y_train)\n",
    "y_pred_svm = svm_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077a3b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "svm_accuracy = accuracy_score(y_test, y_pred_svm)\n",
    "print(f\"SVM Test Accuracy: {svm_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65528f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "rf_accuracy = accuracy_score(y_test, y_pred_rf)\n",
    "print(f\"Random Forest Test Accuracy: {rf_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd7d485",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8cb255",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "rf_accuracy = accuracy_score(y_test, y_pred_rf)\n",
    "print(f\"Random Forest Test Accuracy: {rf_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "683df85c",
   "metadata": {},
   "source": [
    "### One hot encoding for neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d93f5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_one_hot = tf.keras.utils.to_categorical(y, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ce4244",
   "metadata": {},
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4acbb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y_one_hot, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6610f4e6",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7d7e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import BatchNormalization\n",
    "BatchNormalization()\n",
    "\n",
    "def create_model(input_size):\n",
    "    model = Sequential([\n",
    "        Dense(256, activation='relu', input_shape=(input_size,)),\n",
    "        Dropout(0.3),\n",
    "        BatchNormalization(),\n",
    "        Dense(128, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n",
    "        Dropout(0.3),\n",
    "        BatchNormalization(),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        Dense(3, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "input_size = X_train.shape[1]\n",
    "model = create_model(input_size)\n",
    "model.fit(X_train, y_train, epochs=200, batch_size=32, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e34605f",
   "metadata": {},
   "source": [
    "### Evaluation of neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81560139",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {accuracy}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mygpuenv",
   "language": "python",
   "name": "your_environment_name"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
